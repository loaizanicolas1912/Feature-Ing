{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 3. Preprocesamiento de datos</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>3. Métodos de remuestreo</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Librerías y CSV](#section11)\n",
    "* [2. Validación cruzada](#section2)\n",
    "    * [2.1. _k_-fold Cross Validation](#section21)\n",
    "    * [2.2. Validación cruzada repetida](#section22)\n",
    "    * [2.3. Validación cruzada dejando uno fuera](#section23)\n",
    "* [3. División en porcentaje](#section3)\n",
    "    * [3.1. División en porcentaje train/test](#section31)\n",
    "    * [3.2. División train/test repetidos aleatoriamente](#section32)\n",
    "* [4. Qué técnica usar](#section4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La evaluación es una estimación que podemos usar para hablar sobre qué tan bien creemos que el algoritmo realmente puede funcionar en la práctica. No es una garantía de rendimiento. Una vez que estimamos el rendimiento de nuestro algoritmo, podemos volver a entrenar el algoritmo final en todo el conjunto de datos de entrenamiento y prepararlo para su uso operativo. A continuación, veremos cuatro técnicas diferentes que podemos usar para dividir nuestro conjunto de datos de entrenamiento y crear estimaciones útiles de rendimiento para nuestros algoritmos de Machine Learning:\n",
    "* Cómo dividir un conjunto de datos en subconjuntos por porcentaje para entrenamiento/validación.\n",
    "* Cómo evaluar la robustez del modelo utilizando la validación cruzada, k-fold, con y sin repeticiones.\n",
    "* Cómo evaluar la robustez del modelo usando una validación cruzada dejando uno fuera (LOOCV).\n",
    "* División en train/test repetidos aleatoriamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Librerías y CSV</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre cargamos el CSV que vamos a utilizar. Así mismo, vamos a cargar las librerías principales que utilizaremos en esta sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "filename = \"data/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Validación cruzada</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada es un proceso en la que se realizan $K$ particiones o **folds** de la base de datos y con ellos se realizan $K$ evaluaciones diferentes, de tal forma que todos los casos por lo menos una vez se encuentran en el conjunto de test. Básicamente en la evaluación $i$, la partición $i$ son los casos de test y el resto son los casos de entrenamiento. Finalmente, se realiza una media de los resultados obtenidos en las diferentes evaluaciones. En la siguiente imagen se ve un ejemplo de esto.\n",
    "\n",
    "<img src=\"https://static.oschina.net/uploads/img/201609/26155106_OfXx.png\" alt=\"cross-validation\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. _k_-fold Cross Validation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de validación cruzada de _k-fold_ implica dividir el conjunto de datos en _k_-particiones, también llamados _fold_. Cada subconjunto se mantiene mientras el modelo se entrena en todos los demás particiones. Este proceso se repite hasta que se determina la precisión para cada instancia en el conjunto de datos, y se proporciona una estimación de precisión general. Es un método robusto para estimar la precisión, y el tamaño de _k_ puede ajustar la cantidad de sesgo en la estimación, con valores populares establecidos en 5 y 10. \n",
    "\n",
    "Puede ver que informamos tanto la media como la desviación estándar de la medida de rendimiento. Al resumir las medidas de rendimiento, es una buena práctica resumir la distribución de las medidas, en este caso suponiendo una distribución gaussiana del rendimiento (un supuesto muy razonable) y registrando la desviación estándar y media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy: 77.47% (5.54%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "num_folds= 10\n",
    "seed= 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression(solver = 'lbfgs', max_iter=1000)\n",
    "results = cross_val_score(model, X,Y, cv=kfold)\n",
    "print(f\"Acurracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Validación cruzada repetida</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una extensión de esta técnica de entrenamiento/validación es el poder repetir varias veces el proceso de dividir los datos _k-fold_. En este caso, la precisión final del modelo se toma como la media del número de repeticiones.\n",
    "\n",
    "Al igual que el caso anterior podemos observar que nos informa tanto la media como la desviación estándar de la medida de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy: 77.32% (4.15%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Leave One Out Cross Validation\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "num_folds= 10\n",
    "seed= 7\n",
    "num_repeated=5\n",
    "repeatedKFold = RepeatedKFold(n_splits=num_folds, random_state=seed, n_repeats=num_repeated)\n",
    "model = LogisticRegression(solver = 'lbfgs', max_iter=1000)\n",
    "results = cross_val_score(model, X,Y, cv=repeatedKFold)\n",
    "print(f\"Acurracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Validación cruzada estratificada</font>\n",
    "\n",
    "\n",
    "#### Recordar que esta fue la que se vio en el video de codebasic\n",
    "\n",
    "\n",
    "###### EXPLICACIONE ENTRE EL KFOLD Y EL STRATIFIEDFFOLD Y SUS PARAMETROS\n",
    "##### COMO LO ES EL SHUFFLE\n",
    "\n",
    "\n",
    "\n",
    "#### USAR EN MAYORIA DE LOS CASOS EL STRATIFIEDKKFOL CUANDO TENGAMOS PROBLEMAS DE  CLASIFICACION DONDE EL TARGET ESTE MUY DESBALAENCIADO OSEA MAS VALORES DE 1 QUE DE 0 ETC\n",
    "\n",
    "##### DOCUMENTACION:\n",
    "### https://towardsdatascience.com/how-to-train-test-split-kfold-vs-stratifiedkfold-281767b93869 \n",
    "\n",
    "### https://www.quora.com/Is-it-better-using-training-test-split-or-k-fold-CV-when-we-are-working-with-large-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy: 77.22% (2.46%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "num_folds= 10\n",
    "seed= 7\n",
    "stratifiedKFold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state= seed)\n",
    "model = LogisticRegression(solver = 'lbfgs', max_iter=1000)\n",
    "results = cross_val_score(model, X,Y, cv=stratifiedKFold)\n",
    "print(f\"Acurracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
